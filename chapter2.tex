\chapter{Peer-to-peer Networks and Darknets}


\section{Peer-to-peer Networks}
In this section a short history of the internet leading to the development and spreading of peer-to-peer network architecture is given. It should provide a basic understanding of differences and advantages of P2P network design.

\subsection{From classical client-server architecture to distributed networks}
The internet emerged from several military and sience research networks, with ARPANET as the most commonly known of them. It was planed and designed as a decentralized telecomunication network resiliant to outages. Although its resiliance on a network level, most its services have still a centralized structure. On failure not the whole network will fail, but a service, as a website like \emph{www.tu-darmstadt.de} or its email system, can come unavailable easily.

This originates from the in most protocols and services used client-server architecture. The clients tries to find a single server to send its request to. The server processes the request and sends the response back. If in the time between the server is chosen by the client and it sends the response the server fails, the reqeust fails too. There are several methods in protocol and network design to prevent such failures.

The basic approach is to devide the responsipilities in different independant domains. For example an email server is not responsible for all the emails in the world but only for those of one (or more) domains. Note that such a domain does not necessarily mean a domain name in the DNS system but can be an arbitrary domain like a company, an university or just a group of people.

The next level of reduction of responsibility is to reduce what a single component is responsible for. Avoidance of single-point-of-failures, redundancy, load balancing where single requests are distributed to different servers are the common ones. However, all the approaches on this level scale very badly and therefor are highly expensive when achieving good fault tolerance or dealing with large amount of clients or reqeuests.

Taking the splitting of responsibility to the maximum, every one is responsible for everything. This is basicaly the idea behind the peer-to-peer architecture in which every client is simultaniously a server. Of course not every client is responsible for everything in a network but each of them is participating in the service of the network, serving a fraction of the serving while for each fraction there are multiple servers. Since there is commonly no distinction between clients and servers a participant is called a node or peer.

\subsection{P2P Overlays}



\section{Darknets: privacy preserving P2P overlays}

\subsection{The need for privacy preservation}
why and what data to protect..

\subsection{Trust relation base membership and membership consealment}

\subsection{Forwarding requests and hop-by-hop anonymity}


\section{Darknet characteristics and resulting challenges}

\subsection{Hidden Topology}

\subsection{Difficulties for routing algorythms}

\subsection{


\section{metrices for routing evaluation}



\section{Measurement methods for networks}

\subsection{Full blown test environment or mathematical model evalution?}

\subsection{Inbetween: emulation and simulation}

\subsection{Applicability on darknets}



\section{Survey of previous darknets}


